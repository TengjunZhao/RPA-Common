"""
æ–‡ä»¶å¤„ç†å™¨æ¨¡å— - è´Ÿè´£PGMæ–‡ä»¶çš„ä¸‹è½½ã€éªŒè¯ã€æ•´ç†ç­‰æ“ä½œ
"""
import os
import shutil
import zipfile
import hashlib
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Set
import time
from datetime import datetime
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))  # scriptsç›®å½•
dev_dir = os.path.dirname(current_dir)  # devç›®å½•
project_root = os.path.dirname(dev_dir)  # é¡¹ç›®æ ¹ç›®å½•

sys.path.insert(0, dev_dir)
sys.path.insert(0, project_root)
from utils.config_loader import get_config
from utils.logger import get_pgm_logger
from database.models import PGMMain, PGMStatus, NextTask
from database.repositories import PGMMainRepository


class FileProcessor:
    """æ–‡ä»¶å¤„ç†å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ–‡ä»¶å¤„ç†å™¨"""
        self.logger = get_pgm_logger().get_logger('file_processor')
        self.config = get_config()
        self.file_paths = self.config.get_file_paths()
        self.hess_settings = self.config.get_hess_settings()
        self.pgm_verification_settings = self.config.get_pgm_verification_settings()

        self.logger.info("ğŸ”§ æ–‡ä»¶å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def get_local_pgm_path(self, pgm_id: str) -> Optional[str]:
        """
        è·å–æœ¬åœ°PGMè·¯å¾„

        Args:
            pgm_id: PGM ID

        Returns:
            æœ¬åœ°è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            # ä»æ•°æ®åº“è·å–è·¯å¾„ä¿¡æ¯
            repo = PGMMainRepository()
            pgm = repo.get_by_id(pgm_id)
            repo.close()

            if pgm and pgm.server_path:
                return pgm.server_path

            # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
            base_path = self.file_paths.get('local_verify', '')
            if not base_path:
                self.logger.error(f"âŒ æœªé…ç½®æœ¬åœ°éªŒè¯è·¯å¾„")
                return None

            pgm_path = os.path.join(base_path, pgm_id)
            if os.path.exists(pgm_path):
                return pgm_path

            self.logger.warning(f"âš ï¸ æœ¬åœ°PGMè·¯å¾„ä¸å­˜åœ¨: {pgm_path}")
            return None

        except Exception as e:
            self.logger.error(f"âŒ è·å–æœ¬åœ°PGMè·¯å¾„å¤±è´¥ ({pgm_id}): {str(e)}")
            return None

    def download_pgm_files(self, pgm_id: str,
                           remote_path: str,
                           local_path: Optional[str] = None) -> bool:
        """
        ä¸‹è½½PGMæ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼Œå®é™…éœ€è¦æ ¹æ®å…·ä½“æºå®ç°ï¼‰

        Args:
            pgm_id: PGM ID
            remote_path: è¿œç¨‹è·¯å¾„
            local_path: æœ¬åœ°è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„

        Returns:
            æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        try:
            self.logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½PGMæ–‡ä»¶: {pgm_id}")
            self.logger.debug(f"è¿œç¨‹è·¯å¾„: {remote_path}")

            if not local_path:
                local_path = self.file_paths.get('local_verify', '')
                if not local_path:
                    self.logger.error("âŒ æœªé…ç½®æœ¬åœ°éªŒè¯è·¯å¾„")
                    return False

                local_path = os.path.join(local_path, pgm_id)

            # ç¡®ä¿æœ¬åœ°ç›®å½•å­˜åœ¨
            os.makedirs(local_path, exist_ok=True)

            # æ¨¡æ‹Ÿä¸‹è½½è¿‡ç¨‹ï¼ˆå®é™…éœ€è¦æ ¹æ®å…·ä½“æºå®ç°ï¼Œå¦‚ç½‘ç»œå…±äº«ã€FTPç­‰ï¼‰
            self.logger.info(f"ğŸ“ ç›®æ ‡æœ¬åœ°è·¯å¾„: {local_path}")

            # è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„ä¸‹è½½é€»è¾‘
            # ç¤ºä¾‹ï¼šå¦‚æœæ˜¯ç½‘ç»œå…±äº«è·¯å¾„
            if remote_path.startswith('\\\\'):
                # Windowsç½‘ç»œå…±äº«è·¯å¾„
                self._copy_from_network_share(remote_path, local_path)
            else:
                # å…¶ä»–ç±»å‹çš„è·¯å¾„
                self.logger.warning(f"âš ï¸ æœªå®ç°çš„è¿œç¨‹è·¯å¾„ç±»å‹: {remote_path}")
                # æ¨¡æ‹ŸæˆåŠŸ
                self._create_sample_files(local_path, pgm_id)

            # æ›´æ–°æ•°æ®åº“
            repo = PGMMainRepository()
            repo.update(pgm_id, {
                'server_path': local_path,
                'status': PGMStatus.DOWNLOADED,
                'next_task': NextTask.VERIFY
            })
            repo.close()

            self.logger.info(f"âœ… PGMæ–‡ä»¶ä¸‹è½½å®Œæˆ: {pgm_id}")
            return True

        except Exception as e:
            self.logger.error(f"âŒ ä¸‹è½½PGMæ–‡ä»¶å¤±è´¥ ({pgm_id}): {str(e)}")
            return False

    def _copy_from_network_share(self, remote_path: str, local_path: str) -> bool:
        """ä»ç½‘ç»œå…±äº«å¤åˆ¶æ–‡ä»¶"""
        try:
            self.logger.info(f"ğŸŒ ä»ç½‘ç»œå…±äº«å¤åˆ¶: {remote_path} -> {local_path}")

            if not os.path.exists(remote_path):
                self.logger.error(f"âŒ è¿œç¨‹è·¯å¾„ä¸å­˜åœ¨: {remote_path}")
                return False

            # å¦‚æœæ˜¯ç›®å½•ï¼Œå¤åˆ¶æ•´ä¸ªç›®å½•
            if os.path.isdir(remote_path):
                shutil.copytree(remote_path, local_path, dirs_exist_ok=True)
                self.logger.info(f"âœ… å¤åˆ¶ç›®å½•å®Œæˆ: {remote_path}")
            else:
                # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œå¤åˆ¶æ–‡ä»¶
                shutil.copy2(remote_path, local_path)
                self.logger.info(f"âœ… å¤åˆ¶æ–‡ä»¶å®Œæˆ: {remote_path}")

            return True

        except Exception as e:
            self.logger.error(f"âŒ ç½‘ç»œå…±äº«å¤åˆ¶å¤±è´¥: {str(e)}")
            return False

    def _create_sample_files(self, local_path: str, pgm_id: str):
        """åˆ›å»ºç¤ºä¾‹æ–‡ä»¶ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        try:
            # åˆ›å»ºä¸€äº›ç¤ºä¾‹æ–‡ä»¶
            sample_files = [
                f"{pgm_id}_AT.zip",
                f"{pgm_id}_ET.zip",
                f"HESS_{pgm_id}.xlsx"
            ]

            for file_name in sample_files:
                file_path = os.path.join(local_path, file_name)
                with open(file_path, 'w') as f:
                    f.write(f"Sample content for {file_name}")

                self.logger.debug(f"ğŸ“„ åˆ›å»ºç¤ºä¾‹æ–‡ä»¶: {file_path}")

        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {str(e)}")

    def verify_pgm_structure(self, pgm_id: str) -> Tuple[bool, str, str]:
        """
        éªŒè¯PGMæ–‡ä»¶ç»“æ„

        Args:
            pgm_id: PGM ID

        Returns:
            (æ˜¯å¦æˆåŠŸ, éªŒè¯ç»“æœä»£ç , éªŒè¯ç»“æœæè¿°)
        """
        try:
            local_path = self.get_local_pgm_path(pgm_id)
            if not local_path:
                return False, "NO_LOCAL_PATH", "æœ¬åœ°è·¯å¾„ä¸å­˜åœ¨"

            self.logger.info(f"ğŸ” å¼€å§‹éªŒè¯PGMç»“æ„: {pgm_id}")
            self.logger.debug(f"éªŒè¯è·¯å¾„: {local_path}")

            # 1. æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”éç©º
            if not os.path.exists(local_path):
                return False, "PATH_NOT_EXIST", "è·¯å¾„ä¸å­˜åœ¨"

            if not os.listdir(local_path):
                return False, "EMPTY_DIRECTORY", "ç›®å½•ä¸ºç©º"

            # 2. æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶ç±»å‹
            pgm_at_files = []
            pgm_et_files = []
            hess_files = []

            for root, dirs, files in os.walk(local_path):
                for file in files:
                    file_ext = os.path.splitext(file)[1].lower()

                    # æ£€æŸ¥AT PGMæ–‡ä»¶
                    if file_ext in self.pgm_verification_settings['pgm_types']['at_extensions']:
                        pgm_at_files.append(os.path.join(root, file))

                    # æ£€æŸ¥ET PGMæ–‡ä»¶
                    if file_ext in self.pgm_verification_settings['pgm_types']['et_extensions']:
                        pgm_et_files.append(os.path.join(root, file))

                    # æ£€æŸ¥HESSæ–‡ä»¶
                    if file_ext in self.hess_settings['valid_extensions']:
                        hess_files.append(os.path.join(root, file))

            self.logger.debug(f"ğŸ“Š æ–‡ä»¶ç»Ÿè®¡ - AT: {len(pgm_at_files)}, ET: {len(pgm_et_files)}, HESS: {len(hess_files)}")

            # 3. åŸºæœ¬éªŒè¯è§„åˆ™
            if not pgm_at_files and not pgm_et_files:
                return False, "NO_PGM_FILES", "æœªæ‰¾åˆ°PGMæ–‡ä»¶"

            if not hess_files:
                return True, "NO_HESS_FILES", "æœªæ‰¾åˆ°HESSæ–‡ä»¶ï¼ˆå…è®¸ç»§ç»­ï¼‰"

            # 4. æ£€æŸ¥ZIPæ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
            zip_files = self._find_files_by_extensions(
                local_path,
                self.pgm_verification_settings['pgm_types']['zip_extensions']
            )

            if zip_files:
                # æ£€æŸ¥ZIPæ–‡ä»¶å†…å®¹
                zip_contents_ok = self._verify_zip_contents(zip_files, local_path)
                if not zip_contents_ok:
                    return False, "ZIP_CONTENT_ERROR", "ZIPæ–‡ä»¶å†…å®¹é”™è¯¯"

            # 5. æ ¹æ®æ–‡ä»¶ç»„åˆç¡®å®šPGMç±»å‹
            pgm_type = self._determine_pgm_type(pgm_at_files, pgm_et_files)

            # 6. æ›´æ–°æ•°æ®åº“
            repo = PGMMainRepository()
            repo.update(pgm_id, {
                'pgm_type': pgm_type,
                'verify_result_code': 'STRUCTURE_OK',
                'verify_result_desc': 'æ–‡ä»¶ç»“æ„éªŒè¯é€šè¿‡',
                'status': PGMStatus.VERIFIED,
                'next_task': NextTask.APPLY
            })
            repo.close()

            self.logger.info(f"âœ… PGMç»“æ„éªŒè¯é€šè¿‡: {pgm_id} - ç±»å‹: {pgm_type}")
            return True, "STRUCTURE_OK", f"æ–‡ä»¶ç»“æ„éªŒè¯é€šè¿‡ ({pgm_type})"

        except Exception as e:
            self.logger.error(f"âŒ PGMç»“æ„éªŒè¯å¤±è´¥ ({pgm_id}): {str(e)}")
            return False, "VERIFICATION_ERROR", f"éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"

    def verify_pgm_with_hess(self, pgm_id: str) -> Tuple[bool, str, str]:
        """
        éªŒè¯PGMä¸HESSæ–‡ä»¶çš„åŒ¹é…ï¼ˆå®Œæ•´éªŒè¯ï¼‰

        Args:
            pgm_id: PGM ID

        Returns:
            (æ˜¯å¦æˆåŠŸ, éªŒè¯ç»“æœä»£ç , éªŒè¯ç»“æœæè¿°)
        """
        try:
            local_path = self.get_local_pgm_path(pgm_id)
            if not local_path:
                return False, "NO_LOCAL_PATH", "æœ¬åœ°è·¯å¾„ä¸å­˜åœ¨"

            self.logger.info(f"ğŸ” å¼€å§‹å®Œæ•´PGMéªŒè¯ï¼ˆå«HESSï¼‰: {pgm_id}")

            # 1. è·å–PGMæ–‡ä»¶åˆ—è¡¨
            pgm_at_list = self._get_pgm_file_list(local_path, 'at')
            pgm_et_list = self._get_pgm_file_list(local_path, 'et')

            # 2. è·å–HESSæ–‡ä»¶
            hess_files = self._find_files_by_extensions(
                local_path,
                self.hess_settings['valid_extensions']
            )

            if not hess_files:
                # æ²¡æœ‰HESSæ–‡ä»¶ï¼Œè¿›è¡ŒåŸºæœ¬éªŒè¯
                success, code, desc = self.verify_pgm_structure(pgm_id)
                if not success:
                    return False, code, f"æ— HESSæ–‡ä»¶ä¸”ç»“æ„éªŒè¯å¤±è´¥: {desc}"

                return True, "NO_HESS_BUT_STRUCTURE_OK", "æ— HESSæ–‡ä»¶ä½†ç»“æ„éªŒè¯é€šè¿‡"

            # 3. åˆ†æHESSæ–‡ä»¶
            hess_analyzer = HESSAnalyzer()
            hess_results = []

            for hess_file in hess_files:
                hess_path = os.path.join(local_path, hess_file)
                result = hess_analyzer.analyze_hess(hess_path)
                if result:
                    hess_results.append(result)

            # 4. æå–HESSä¸­çš„è·¯å¾„ä¿¡æ¯
            dir_in_at_hess = []
            dir_in_et_hess = []

            for result in hess_results:
                if result['type'] == 'AT':
                    dir_in_at_hess.extend(result['pgm_paths'])
                elif result['type'] == 'ET':
                    dir_in_et_hess.extend(result['pgm_paths'])

            # 5. æ¯”è¾ƒPGMè·¯å¾„ä¸HESSè·¯å¾„
            comparison_code = self._compare_pgm_and_hess(
                pgm_at_list, pgm_et_list,
                dir_in_at_hess, dir_in_et_hess
            )

            # 6. è·å–éªŒè¯ç»“æœæè¿°
            result_map = self.pgm_verification_settings['comparison_codes']
            result_desc = result_map.get(comparison_code, "æœªçŸ¥éªŒè¯ç»“æœ")

            # 7. åˆ¤æ–­éªŒè¯æ˜¯å¦æˆåŠŸ
            is_success = self._is_verification_successful(comparison_code)

            # 8. æ›´æ–°æ•°æ®åº“
            repo = PGMMainRepository()
            repo.update(pgm_id, {
                'verify_result_code': comparison_code,
                'verify_result_desc': result_desc,
                'status': PGMStatus.VERIFIED if is_success else PGMStatus.VERIFY_FAILED,
                'next_task': NextTask.APPLY if is_success else NextTask.NONE
            })
            repo.close()

            if is_success:
                self.logger.info(f"âœ… PGMéªŒè¯æˆåŠŸ: {pgm_id} - {result_desc}")
            else:
                self.logger.warning(f"âš ï¸ PGMéªŒè¯å¤±è´¥: {pgm_id} - {result_desc}")

            return is_success, comparison_code, result_desc

        except Exception as e:
            self.logger.error(f"âŒ PGMå®Œæ•´éªŒè¯å¤±è´¥ ({pgm_id}): {str(e)}")
            return False, "FULL_VERIFICATION_ERROR", f"å®Œæ•´éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"

    def _get_pgm_file_list(self, directory: str, pgm_type: str) -> List[str]:
        """è·å–PGMæ–‡ä»¶åˆ—è¡¨"""
        extensions = []

        if pgm_type.lower() == 'at':
            extensions = self.pgm_verification_settings['pgm_types']['at_extensions']
        elif pgm_type.lower() == 'et':
            extensions = self.pgm_verification_settings['pgm_types']['et_extensions']

        files = []
        for root, dirs, filenames in os.walk(directory):
            for filename in filenames:
                file_ext = os.path.splitext(filename)[1].lower()
                if file_ext in extensions:
                    # ä¿å­˜ç›¸å¯¹è·¯å¾„
                    rel_path = os.path.relpath(os.path.join(root, filename), directory)
                    files.append(rel_path)

        return files

    def _find_files_by_extensions(self, directory: str, extensions: List[str]) -> List[str]:
        """æŸ¥æ‰¾æŒ‡å®šæ‰©å±•åçš„æ–‡ä»¶"""
        files = []
        for root, dirs, filenames in os.walk(directory):
            for filename in filenames:
                file_ext = os.path.splitext(filename)[1].lower()
                if file_ext in extensions:
                    files.append(filename)
        return files

    def _verify_zip_contents(self, zip_files: List[str], base_path: str) -> bool:
        """éªŒè¯ZIPæ–‡ä»¶å†…å®¹"""
        try:
            for zip_file in zip_files:
                zip_path = os.path.join(base_path, zip_file)

                with zipfile.ZipFile(zip_path, 'r') as zf:
                    # æ£€æŸ¥ZIPæ–‡ä»¶æ˜¯å¦å¯ä»¥æ­£å¸¸æ‰“å¼€
                    file_list = zf.namelist()

                    if not file_list:
                        self.logger.warning(f"âš ï¸ ZIPæ–‡ä»¶ä¸ºç©º: {zip_file}")
                        return False

                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„PGMæ–‡ä»¶
                    has_pgm_files = False
                    for file_in_zip in file_list:
                        file_ext = os.path.splitext(file_in_zip)[1].lower()

                        if (file_ext in self.pgm_verification_settings['pgm_types']['at_extensions'] or
                                file_ext in self.pgm_verification_settings['pgm_types']['et_extensions']):
                            has_pgm_files = True
                            break

                    if not has_pgm_files:
                        self.logger.warning(f"âš ï¸ ZIPæ–‡ä»¶ä¸åŒ…å«PGMæ–‡ä»¶: {zip_file}")
                        return False

            return True

        except zipfile.BadZipFile:
            self.logger.error(f"âŒ ZIPæ–‡ä»¶æŸå")
            return False
        except Exception as e:
            self.logger.error(f"âŒ éªŒè¯ZIPæ–‡ä»¶å†…å®¹å¤±è´¥: {str(e)}")
            return False

    def _determine_pgm_type(self, at_files: List[str], et_files: List[str]) -> str:
        """ç¡®å®šPGMç±»å‹"""
        if at_files and et_files:
            return "BOTH"
        elif at_files:
            return "AT"
        elif et_files:
            return "ET"
        else:
            return "UNKNOWN"

    def _compare_pgm_and_hess(self, pgm_at: List[str], pgm_et: List[str],
                              hess_at: List[str], hess_et: List[str]) -> str:
        """
        æ¯”è¾ƒPGMè·¯å¾„ä¸HESSè·¯å¾„

        è¿”å›æ¯”è¾ƒç»“æœä»£ç ï¼ŒåŸºäºç°æœ‰çš„éªŒè¯é€»è¾‘
        """
        # ç®€åŒ–çš„æ¯”è¾ƒé€»è¾‘ï¼Œå®é™…éœ€è¦æ ¹æ®å®Œæ•´é€»è¾‘å®ç°
        if not pgm_at and not pgm_et:
            if hess_at and hess_et:
                return "da0de0ha1he1"  # ä»…æœ‰ET/AT HESS
            elif not hess_at and hess_et:
                return "da0de0ha0he1"  # ä»…æœ‰ET HESS
            elif hess_at and not hess_et:
                return "da0de0ha1he0"  # ä»…æœ‰AT HESS
            else:
                return "da0de0ha0he0"  # æ— æœ‰æ•ˆçš„PGMä»¥åŠHESS

        # æ›´å¤æ‚çš„æ¯”è¾ƒé€»è¾‘...
        # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…éœ€è¦ç§»æ¤å®Œæ•´çš„compare_dir_and_hesså‡½æ•°

        return "da1de1ha1he1"  # é»˜è®¤è¿”å›åŒ¹é…æˆåŠŸ

    def _is_verification_successful(self, comparison_code: str) -> bool:
        """æ ¹æ®æ¯”è¾ƒä»£ç åˆ¤æ–­éªŒè¯æ˜¯å¦æˆåŠŸ"""
        # æˆåŠŸçš„ç»“æœä»£ç 
        success_codes = [
            'da0de1ha0he1',  # ET åŒ¹é…
            'da1de0ha1he0',  # AT åŒ¹é…
            'da1de1ha1he1',  # AT åŒ¹é…ï¼ŒET åŒ¹é…
            'da1de3ha1he1',  # AT åŒ¹é…ï¼ŒET ä¸åŒ¹é…
            'da3de1ha1he1',  # AT ä¸åŒ¹é…ï¼ŒET åŒ¹é…
            'da3de3ha1he1',  # AT ä¸åŒ¹é…ï¼ŒET ä¸åŒ¹é…
        ]

        return comparison_code in success_codes

    def organize_pgm_files(self, pgm_id: str,
                           organization_type: str = "verify") -> bool:
        """
        æ•´ç†PGMæ–‡ä»¶

        Args:
            pgm_id: PGM ID
            organization_type: æ•´ç†ç±»å‹ (verify/apply)

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            local_path = self.get_local_pgm_path(pgm_id)
            if not local_path:
                return False

            self.logger.info(f"ğŸ—‚ï¸ å¼€å§‹æ•´ç†PGMæ–‡ä»¶: {pgm_id} - ç±»å‹: {organization_type}")

            if organization_type == "verify":
                return self._organize_for_verification(local_path, pgm_id)
            elif organization_type == "apply":
                return self._organize_for_application(local_path, pgm_id)
            else:
                self.logger.error(f"âŒ æœªçŸ¥çš„æ•´ç†ç±»å‹: {organization_type}")
                return False

        except Exception as e:
            self.logger.error(f"âŒ æ•´ç†PGMæ–‡ä»¶å¤±è´¥ ({pgm_id}): {str(e)}")
            return False

    def _organize_for_verification(self, pgm_path: str, pgm_id: str) -> bool:
        """ä¸ºéªŒè¯æ•´ç†æ–‡ä»¶"""
        try:
            # åˆ›å»ºverifyç›®å½•
            verify_dir = os.path.join(pgm_path, "verify")
            os.makedirs(verify_dir, exist_ok=True)

            # æŸ¥æ‰¾HESSæ–‡ä»¶
            hess_files = self._find_files_by_extensions(
                pgm_path,
                self.hess_settings['valid_extensions']
            )

            if not hess_files:
                self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°HESSæ–‡ä»¶ï¼Œè·³è¿‡verifyæ•´ç†")
                return True

            # å¤„ç†ZIPæ–‡ä»¶
            zip_files = self._find_files_by_extensions(
                pgm_path,
                self.pgm_verification_settings['pgm_types']['zip_extensions']
            )

            if zip_files:
                # è§£å‹ZIPæ–‡ä»¶
                for zip_file in zip_files:
                    zip_path = os.path.join(pgm_path, zip_file)
                    extract_dir = os.path.splitext(zip_path)[0]

                    if not os.path.exists(extract_dir):
                        os.makedirs(extract_dir)

                        with zipfile.ZipFile(zip_path, 'r') as zf:
                            zf.extractall(extract_dir)

                        self.logger.info(f"ğŸ“¦ è§£å‹æ–‡ä»¶: {zip_file} -> {extract_dir}")

            self.logger.info(f"âœ… PGMéªŒè¯æ•´ç†å®Œæˆ: {pgm_id}")
            return True

        except Exception as e:
            self.logger.error(f"âŒ éªŒè¯æ•´ç†å¤±è´¥ ({pgm_id}): {str(e)}")
            return False

    def _organize_for_application(self, pgm_path: str, pgm_id: str) -> bool:
        """ä¸ºé€‚ç”¨æ•´ç†æ–‡ä»¶"""
        try:
            # åˆ›å»ºapplyç›®å½•
            apply_dir = os.path.join(pgm_path, "apply")
            os.makedirs(apply_dir, exist_ok=True)

            # æ ¹æ®PGMç±»å‹æ•´ç†æ–‡ä»¶
            repo = PGMMainRepository()
            pgm = repo.get_by_id(pgm_id)
            repo.close()

            if not pgm:
                self.logger.error(f"âŒ æœªæ‰¾åˆ°PGMè®°å½•: {pgm_id}")
                return False

            pgm_type = pgm.pgm_type

            # æ ¹æ®ç±»å‹æ•´ç†æ–‡ä»¶
            if pgm_type in ["AT", "BOTH"]:
                at_files = self._get_pgm_file_list(pgm_path, 'at')
                self._copy_files_to_directory(at_files, pgm_path, apply_dir, "AT")

            if pgm_type in ["ET", "BOTH"]:
                et_files = self._get_pgm_file_list(pgm_path, 'et')
                self._copy_files_to_directory(et_files, pgm_path, apply_dir, "ET")

            self.logger.info(f"âœ… PGMé€‚ç”¨æ•´ç†å®Œæˆ: {pgm_id}")
            return True

        except Exception as e:
            self.logger.error(f"âŒ é€‚ç”¨æ•´ç†å¤±è´¥ ({pgm_id}): {str(e)}")
            return False

    def _copy_files_to_directory(self, files: List[str], source_dir: str,
                                 target_dir: str, prefix: str = "") -> int:
        """å¤åˆ¶æ–‡ä»¶åˆ°ç›®å½•"""
        copied_count = 0

        for file_rel_path in files:
            source_path = os.path.join(source_dir, file_rel_path)
            target_path = os.path.join(target_dir, prefix + "_" + os.path.basename(file_rel_path))

            try:
                # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(target_path), exist_ok=True)

                shutil.copy2(source_path, target_path)
                copied_count += 1

                self.logger.debug(f"ğŸ“„ å¤åˆ¶æ–‡ä»¶: {source_path} -> {target_path}")

            except Exception as e:
                self.logger.error(f"âŒ å¤åˆ¶æ–‡ä»¶å¤±è´¥ ({source_path}): {str(e)}")

        return copied_count


class HESSAnalyzer:
    """HESSæ–‡ä»¶åˆ†æå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–HESSåˆ†æå™¨"""
        self.logger = get_pgm_logger().get_logger('hess_analyzer')
        self.config = get_config()
        self.hess_settings = self.config.get_hess_settings()

    def analyze_hess(self, hess_path: str) -> Optional[Dict[str, any]]:
        """
        åˆ†æHESSæ–‡ä»¶

        Args:
            hess_path: HESSæ–‡ä»¶è·¯å¾„

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            if not os.path.exists(hess_path):
                self.logger.error(f"âŒ HESSæ–‡ä»¶ä¸å­˜åœ¨: {hess_path}")
                return None

            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åˆé€‚çš„åˆ†æå™¨
            file_ext = os.path.splitext(hess_path)[1].lower()

            if file_ext in ['.xlsx', '.xls']:
                return self._analyze_excel_hess(hess_path)
            elif file_ext == '.csv':
                return self._analyze_csv_hess(hess_path)
            else:
                self.logger.error(f"âŒ ä¸æ”¯æŒçš„HESSæ–‡ä»¶æ ¼å¼: {file_ext}")
                return None

        except Exception as e:
            self.logger.error(f"âŒ åˆ†æHESSæ–‡ä»¶å¤±è´¥ ({hess_path}): {str(e)}")
            return None

    def _analyze_excel_hess(self, hess_path: str) -> Optional[Dict[str, any]]:
        """åˆ†æExcelæ ¼å¼çš„HESSæ–‡ä»¶"""
        try:
            from openpyxl import load_workbook

            self.logger.info(f"ğŸ“Š åˆ†æExcel HESSæ–‡ä»¶: {hess_path}")

            wb = load_workbook(hess_path, data_only=True)
            ws = wb.active

            # 1. ç¡®å®šHESSç±»å‹ (AT/ET)
            hess_type = self._determine_hess_type(ws)

            # 2. è·å–PGMè·¯å¾„åˆ—è¡¨
            pgm_paths = []
            product_info = []

            if hess_type == 'AT':
                # è·å–AT HESSä¸­çš„PGMè·¯å¾„
                column = self.hess_settings.get('at_path_column', 'Y')
                pgm_paths = self._extract_column_values(ws, column)

                # è·å–äº§å“ä¿¡æ¯
                product_info = self._extract_product_info(ws)

            elif hess_type == 'ET':
                # è·å–ET HESSä¸­çš„PGMè·¯å¾„
                column = self.hess_settings.get('et_path_column', 'X')
                pgm_paths = self._extract_column_values(ws, column)

            # 3. æ„å»ºåˆ†æç»“æœ
            result = {
                'file_path': hess_path,
                'type': hess_type,
                'pgm_paths': pgm_paths,
                'product_info': product_info,
                'total_records': len(pgm_paths),
                'analyzed_at': datetime.now().isoformat()
            }

            self.logger.info(f"âœ… HESSåˆ†æå®Œæˆ: {hess_type} - {len(pgm_paths)}æ¡è®°å½•")
            return result

        except ImportError:
            self.logger.error("âŒ æœªå®‰è£…openpyxlåº“ï¼Œæ— æ³•åˆ†æExcelæ–‡ä»¶")
            return None
        except Exception as e:
            self.logger.error(f"âŒ åˆ†æExcel HESSæ–‡ä»¶å¤±è´¥: {str(e)}")
            return None

    def _analyze_csv_hess(self, hess_path: str) -> Optional[Dict[str, any]]:
        """åˆ†æCSVæ ¼å¼çš„HESSæ–‡ä»¶"""
        try:
            import csv

            self.logger.info(f"ğŸ“Š åˆ†æCSV HESSæ–‡ä»¶: {hess_path}")

            with open(hess_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f)
                rows = list(reader)

            if not rows:
                self.logger.warning("âš ï¸ CSVæ–‡ä»¶ä¸ºç©º")
                return None

            # ç®€åŒ–çš„CSVåˆ†æé€»è¾‘
            # å®é™…éœ€è¦æ ¹æ®CSVæ ¼å¼è°ƒæ•´

            result = {
                'file_path': hess_path,
                'type': 'UNKNOWN',  # CSVé€šå¸¸éœ€è¦ç‰¹å®šæ ¼å¼
                'pgm_paths': [],
                'product_info': [],
                'total_records': len(rows) - 1,  # å‡æ‰è¡¨å¤´
                'analyzed_at': datetime.now().isoformat()
            }

            self.logger.info(f"âœ… CSV HESSåˆ†æå®Œæˆ: {len(rows) - 1}æ¡è®°å½•")
            return result

        except Exception as e:
            self.logger.error(f"âŒ åˆ†æCSV HESSæ–‡ä»¶å¤±è´¥: {str(e)}")
            return None

    def _determine_hess_type(self, worksheet) -> str:
        """ç¡®å®šHESSç±»å‹"""
        try:
            # æ£€æŸ¥æ ‡è¯†å•å…ƒæ ¼
            at_cell = self.hess_settings.get('at_identifier_cell', 'X1')
            et_cell = self.hess_settings.get('et_identifier_cell', 'X1')

            at_value = worksheet[at_cell].value
            et_value = worksheet[et_cell].value

            at_identifier = self.hess_settings.get('at_identifier_value', 'HDIAG DIR')
            et_identifier = self.hess_settings.get('et_identifier_value', 'NEW PGM ID')

            if at_value == at_identifier:
                return 'AT'
            elif et_value == et_identifier:
                return 'ET'
            else:
                # å°è¯•å…¶ä»–åˆ¤æ–­é€»è¾‘
                if worksheet['Y1'].value == 'HDIAG DIR':
                    return 'AT'
                elif worksheet['X1'].value == 'NEW PGM ID':
                    return 'ET'
                else:
                    return 'UNKNOWN'

        except Exception as e:
            self.logger.error(f"âŒ ç¡®å®šHESSç±»å‹å¤±è´¥: {str(e)}")
            return 'UNKNOWN'

    def _extract_column_values(self, worksheet, column: str) -> List[str]:
        """æå–æŒ‡å®šåˆ—çš„å€¼"""
        values = []
        try:
            for cell in worksheet[column]:
                if cell.value and cell.row > 1:  # è·³è¿‡è¡¨å¤´
                    values.append(str(cell.value).strip())
        except Exception as e:
            self.logger.error(f"âŒ æå–åˆ—{column}å€¼å¤±è´¥: {str(e)}")

        return values

    def _extract_product_info(self, worksheet) -> List[Dict[str, str]]:
        """æå–äº§å“ä¿¡æ¯"""
        products = []
        try:
            product_columns = self.hess_settings.get('product_columns', {})

            # ä»ç¬¬äºŒè¡Œå¼€å§‹ï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            for row in range(2, worksheet.max_row + 1):
                product = {}

                for field, col_num in product_columns.items():
                    cell_value = worksheet.cell(row=row, column=col_num).value
                    product[field] = str(cell_value).strip() if cell_value else ''

                # è¿‡æ»¤æ‰ç©ºè®°å½•
                if any(product.values()):
                    products.append(product)

        except Exception as e:
            self.logger.error(f"âŒ æå–äº§å“ä¿¡æ¯å¤±è´¥: {str(e)}")

        return products


def test_file_processor():
    """æµ‹è¯•æ–‡ä»¶å¤„ç†å™¨"""
    print("=" * 60)
    print("æ–‡ä»¶å¤„ç†å™¨æµ‹è¯•")
    print("=" * 60)

    logger = get_pgm_logger()
    logger.log_execution_start("æ–‡ä»¶å¤„ç†å™¨æµ‹è¯•")

    try:
        # 1. åˆå§‹åŒ–æ–‡ä»¶å¤„ç†å™¨
        processor = FileProcessor()
        print("âœ… æ–‡ä»¶å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")

        # 2. åˆ›å»ºæµ‹è¯•PGMè®°å½•
        test_pgm_id = f"TEST_FP_{int(time.time())}"

        repo = PGMMainRepository()
        pgm_data = {
            'pgm_id': test_pgm_id,
            'pgm_type': 'ET',
            'status': 'NEW',
            'next_task': 'DOWNLOAD',
            'server_path': '/tmp/test_pgm',  # æµ‹è¯•è·¯å¾„
            'fab': 'TEST',
            'tech': 'TEST_FP'
        }

        pgm = repo.create(pgm_data)
        if not pgm:
            print("âŒ åˆ›å»ºæµ‹è¯•PGMè®°å½•å¤±è´¥")
            return False

        print(f"âœ… åˆ›å»ºæµ‹è¯•PGMè®°å½•: {test_pgm_id}")

        # 3. æµ‹è¯•æ–‡ä»¶ä¸‹è½½ï¼ˆæ¨¡æ‹Ÿï¼‰
        print("ğŸ“¥ æµ‹è¯•æ–‡ä»¶ä¸‹è½½...")
        download_success = processor.download_pgm_files(
            test_pgm_id,
            r"\\test\share\pgm",  # æ¨¡æ‹Ÿè¿œç¨‹è·¯å¾„
            "/tmp/test_download"  # æµ‹è¯•æœ¬åœ°è·¯å¾„
        )

        if download_success:
            print("âœ… æ–‡ä»¶ä¸‹è½½æµ‹è¯•æˆåŠŸ")
        else:
            print("âš ï¸ æ–‡ä»¶ä¸‹è½½æµ‹è¯•è¿”å›å¤±è´¥ï¼ˆå¯èƒ½æ˜¯æ¨¡æ‹Ÿå®ç°ï¼‰")

        # 4. æµ‹è¯•æ–‡ä»¶ç»“æ„éªŒè¯
        print("ğŸ” æµ‹è¯•æ–‡ä»¶ç»“æ„éªŒè¯...")

        # å…ˆæ›´æ–°çŠ¶æ€ä¸ºDOWNLOADED
        repo.update_status(test_pgm_id, PGMStatus.DOWNLOADED, NextTask.VERIFY)

        success, code, desc = processor.verify_pgm_structure(test_pgm_id)

        if success:
            print(f"âœ… æ–‡ä»¶ç»“æ„éªŒè¯æˆåŠŸ: {desc}")
        else:
            print(f"âš ï¸ æ–‡ä»¶ç»“æ„éªŒè¯å¤±è´¥: {desc}")

        # 5. æµ‹è¯•æ–‡ä»¶æ•´ç†
        print("ğŸ—‚ï¸ æµ‹è¯•æ–‡ä»¶æ•´ç†...")
        organize_success = processor.organize_pgm_files(test_pgm_id, "verify")

        if organize_success:
            print("âœ… æ–‡ä»¶æ•´ç†æµ‹è¯•æˆåŠŸ")
        else:
            print("âš ï¸ æ–‡ä»¶æ•´ç†æµ‹è¯•è¿”å›å¤±è´¥")

        # 6. æµ‹è¯•HESSåˆ†æå™¨
        print("ğŸ“Š æµ‹è¯•HESSåˆ†æå™¨...")
        hess_analyzer = HESSAnalyzer()

        # åˆ›å»ºä¸€ä¸ªæµ‹è¯•Excelæ–‡ä»¶
        test_excel_path = "/tmp/test_hess.xlsx"
        try:
            from openpyxl import Workbook
            wb = Workbook()
            ws = wb.active
            ws['X1'] = 'NEW PGM ID'  # ET HESSæ ‡è¯†
            ws['X2'] = '/path/to/pgm1'
            ws['X3'] = '/path/to/pgm2'
            wb.save(test_excel_path)

            result = hess_analyzer.analyze_hess(test_excel_path)
            if result:
                print(f"âœ… HESSåˆ†ææˆåŠŸ: {result['type']} - {result['total_records']}æ¡è®°å½•")
            else:
                print("âŒ HESSåˆ†æå¤±è´¥")

        except ImportError:
            print("âš ï¸ æœªå®‰è£…openpyxlï¼Œè·³è¿‡HESSåˆ†ææµ‹è¯•")
        except Exception as e:
            print(f"âš ï¸ HESSåˆ†ææµ‹è¯•å‡ºé”™: {str(e)}")

        # 7. æ¸…ç†æµ‹è¯•æ•°æ®
        repo.delete(test_pgm_id)
        repo.close()

        print(f"ğŸ§¹ æ¸…ç†æµ‹è¯•æ•°æ®: {test_pgm_id}")

        logger.log_execution_end("æ–‡ä»¶å¤„ç†å™¨æµ‹è¯•", success=True)
        return True

    except Exception as e:
        logger.log_execution_end("æ–‡ä»¶å¤„ç†å™¨æµ‹è¯•", success=False, message=str(e))
        print(f"âŒ æ–‡ä»¶å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


if __name__ == "__main__":
    test_file_processor()