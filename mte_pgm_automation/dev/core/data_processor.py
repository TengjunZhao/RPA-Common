"""
æ•°æ®å¤„ç†å™¨ - å®Œæ•´ç‰ˆæœ¬ï¼ˆåŒ…å«æ–‡ä»¶ä¸‹è½½ï¼‰
"""
import os
import json
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import time
import shutil
import requests

from utils.config_loader import get_config
from utils.logger import get_pgm_logger
from database.models import PGMMain, PGMStatus, NextTask, PGMOmsHistory
from database.repositories import PGMMainRepository, PGMOmsHistoryRepository
from core.oms_client import OMSClient, OMSDataProcessor

"""
æ•°æ®å¤„ç†å™¨ - è´Ÿè´£ä»OMSæ•°æ®åˆ›å»ºPGMè®°å½•å¹¶ä¸‹è½½æ–‡ä»¶
"""
import os
import json
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import time
import shutil

from utils.config_loader import get_config
from utils.logger import get_pgm_logger
from database.models import PGMMain, PGMStatus, NextTask, PGMOmsHistory
from database.repositories import PGMMainRepository, PGMOmsHistoryRepository
from core.oms_client import OMSClient


class DataProcessor:
    """OMSæ•°æ®å¤„ç†å’ŒPGMè®°å½•åˆ›å»ºå™¨"""

    def __init__(self, oms_client: OMSClient = None):
        """åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨"""
        self.logger = get_pgm_logger().get_logger('data_processor')
        self.config = get_config()
        self.file_paths = self.config.get_file_paths()
        self.oms_client = oms_client or OMSClient()
        self.pgm_repo = PGMMainRepository()
        self.oms_repo = PGMOmsHistoryRepository()

        self.logger.info("ğŸ”§ æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def fetch_and_process_new_pgms(self) -> Dict[str, any]:
        """
        è·å–å¹¶å¤„ç†æ–°PGMï¼ˆå®Œæ•´æµç¨‹ï¼‰

        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        try:
            self.logger.info("ğŸ”„ å¼€å§‹å®Œæ•´PGMå¤„ç†æµç¨‹")

            results = {
                'total_drafts': 0,
                'new_pgms_created': 0,
                'existing_pgms_updated': 0,
                'files_downloaded': 0,
                'download_errors': 0,
                'process_errors': 0,
                'pgm_details': []
            }

            # 1. ä»OMSè·å–æ‰€æœ‰è‰ç¨¿ID
            all_drafts = self._get_all_draft_ids_from_oms()
            results['total_drafts'] = len(all_drafts)

            if not all_drafts:
                self.logger.warning("âš ï¸ æœªä»OMSè·å–åˆ°ä»»ä½•è‰ç¨¿ID")
                return results

            self.logger.info(f"ğŸ“Š ä»OMSè·å–åˆ° {len(all_drafts)} ä¸ªè‰ç¨¿ID")

            # 2. å¤„ç†æ¯ä¸ªè‰ç¨¿ID
            for draft_id in all_drafts:
                try:
                    draft_result = self._process_single_draft(draft_id)
                    results['pgm_details'].append(draft_result)

                    if draft_result['success']:
                        if draft_result['action'] == 'created':
                            results['new_pgms_created'] += 1
                        elif draft_result['action'] == 'updated':
                            results['existing_pgms_updated'] += 1

                        results['files_downloaded'] += draft_result['files_downloaded']
                        results['download_errors'] += draft_result['download_errors']
                    else:
                        results['process_errors'] += 1

                except Exception as e:
                    self.logger.error(f"âŒ å¤„ç†è‰ç¨¿å¤±è´¥ ({draft_id}): {str(e)}")
                    results['process_errors'] += 1
                    results['pgm_details'].append({
                        'draft_id': draft_id,
                        'success': False,
                        'error': str(e)
                    })

            # 3. æ±‡æ€»ç»“æœ
            self.logger.info(
                f"ğŸ“Š å®Œæ•´å¤„ç†å®Œæˆ - æ–°å»ºPGM: {results['new_pgms_created']}, æ–‡ä»¶ä¸‹è½½: {results['files_downloaded']}, é”™è¯¯: {results['process_errors']}")

            return results

        except Exception as e:
            self.logger.error(f"âŒ å®Œæ•´å¤„ç†æµç¨‹å¤±è´¥: {str(e)}")
            return {'total_drafts': 0, 'new_pgms_created': 0, 'process_errors': 1, 'error': str(e)}

    def _get_all_draft_ids_from_oms(self) -> List[str]:
        """ä»OMSè·å–æ‰€æœ‰è‰ç¨¿ID"""
        try:
            # ä½¿ç”¨ç°æœ‰çš„OMSå®¢æˆ·ç«¯è·å–åˆ†å‘çŠ¶æ€
            oms_data = self.oms_client.get_pgm_distribution_status()

            if not oms_data:
                return []

            # æå–å”¯ä¸€çš„draft_id
            draft_ids = set()
            for item in oms_data:
                draft_id = item.get('draftId')
                if draft_id:
                    draft_ids.add(str(draft_id))

            # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
            sorted_drafts = sorted(list(draft_ids))

            self.logger.info(f"ğŸ“‹ æå–åˆ° {len(sorted_drafts)} ä¸ªå”¯ä¸€è‰ç¨¿ID")
            return sorted_drafts

        except Exception as e:
            self.logger.error(f"âŒ è·å–è‰ç¨¿IDå¤±è´¥: {str(e)}")
            return []

    def _process_single_draft(self, draft_id: str) -> Dict[str, any]:
        """
        å¤„ç†å•ä¸ªè‰ç¨¿

        Args:
            draft_id: è‰ç¨¿ID

        Returns:
            å¤„ç†ç»“æœ
        """
        self.logger.info(f"ğŸ” å¤„ç†è‰ç¨¿: {draft_id}")

        result = {
            'draft_id': draft_id,
            'success': False,
            'action': 'skipped',
            'pgm_id': None,
            'pgm_type': None,
            'files_downloaded': 0,
            'download_errors': 0,
            'server_path': None,
            'message': ''
        }

        try:
            # 1. æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦å·²å­˜åœ¨è¯¥PGM
            server_path = self._get_server_path_for_draft(draft_id)
            result['server_path'] = server_path

            if os.path.exists(server_path) and os.listdir(server_path):
                # ç›®å½•å·²å­˜åœ¨ä¸”éç©ºï¼Œè·³è¿‡
                result['success'] = True
                result['action'] = 'skipped'
                result['message'] = 'æœåŠ¡å™¨å·²å­˜åœ¨è¯¥PGMæ–‡ä»¶'
                self.logger.info(f"â­ï¸ è·³è¿‡å·²å­˜åœ¨çš„PGM: {draft_id}")
                return result

            # 2. ç¡®å®šPGMç±»å‹ï¼ˆéœ€è¦ä»OMSè·å–è¯¦ç»†ä¿¡æ¯ï¼‰
            pgm_type = self._determine_pgm_type_for_draft(draft_id)
            result['pgm_type'] = pgm_type

            # 3. ç”ŸæˆPGM ID
            pgm_id = self._generate_pgm_id(draft_id, pgm_type)
            result['pgm_id'] = pgm_id

            # 4. æ›´æ–°æœåŠ¡å™¨è·¯å¾„
            server_path = self._create_server_path(pgm_id)
            result['server_path'] = server_path

            # 5. åˆ›å»ºæˆ–æ›´æ–°PGMè®°å½•
            existing_pgm = self.pgm_repo.get_by_id(pgm_id)

            if existing_pgm:
                # æ›´æ–°ç°æœ‰è®°å½•
                updated = self._update_existing_pgm(existing_pgm, draft_id, pgm_type)
                result['action'] = 'updated' if updated else 'update_failed'
            else:
                # åˆ›å»ºæ–°è®°å½•
                created = self._create_new_pgm(pgm_id, pgm_type, draft_id, server_path)
                result['action'] = 'created' if created else 'create_failed'

            if result['action'] in ['created', 'updated']:
                result['success'] = True

                # 6. ä¸‹è½½æ–‡ä»¶
                download_result = self._download_files_for_draft(draft_id, server_path)
                result['files_downloaded'] = download_result['downloaded']
                result['download_errors'] = download_result['errors']

                if download_result['downloaded'] > 0:
                    result['message'] = f'æˆåŠŸå¤„ç†ï¼Œä¸‹è½½{download_result["downloaded"]}ä¸ªæ–‡ä»¶'
                else:
                    result['message'] = 'æˆåŠŸå¤„ç†ï¼Œä½†æœªä¸‹è½½åˆ°æ–‡ä»¶'

            return result

        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†è‰ç¨¿å¤±è´¥ ({draft_id}): {str(e)}")
            result['message'] = f'å¤„ç†å¤±è´¥: {str(e)}'
            return result

    def _get_server_path_for_draft(self, draft_id: str) -> str:
        """è·å–è‰ç¨¿çš„æœåŠ¡å™¨è·¯å¾„"""
        base_path = self.file_paths.get('local_verify', '')
        if not base_path:
            raise ValueError("æœªé…ç½®æœ¬åœ°éªŒè¯è·¯å¾„")

        # ä½¿ç”¨æ—¥æœŸå­ç›®å½•
        date_str = datetime.now().strftime('%Y%m%d')
        draft_path = os.path.join(base_path, date_str, draft_id)

        return draft_path

    def _determine_pgm_type_for_draft(self, draft_id: str) -> str:
        """ä¸ºè‰ç¨¿ç¡®å®šPGMç±»å‹"""
        # è¿™é‡Œéœ€è¦è°ƒç”¨OMS APIè·å–è¯¦ç»†ä¿¡æ¯æ¥ç¡®å®šç±»å‹
        # æš‚æ—¶è¿”å›é»˜è®¤å€¼ï¼Œå®é™…éœ€è¦å®ç°

        # å°è¯•ä»æ•°æ®åº“æŸ¥æ‰¾å†å²è®°å½•
        try:
            # ä»pgm_oms_historyæŸ¥æ‰¾è¯¥draft_idçš„è®°å½•
            session = self.oms_repo.session
            records = session.query(PGMOmsHistory).filter(
                PGMOmsHistory.draft_id == draft_id
            ).all()

            if records:
                for record in records:
                    process_name = record.process_name or ''
                    if 'ET' in process_name.upper():
                        return 'ET'
                    elif 'AT' in process_name.upper():
                        return 'AT'
        except:
            pass

        # é»˜è®¤è¿”å›ET
        return 'ET'

    def _process_single_oms_record(self, oms_record: PGMOmsHistory) -> Dict[str, any]:
        """
        å¤„ç†å•ä¸ªOMSè®°å½•

        Args:
            oms_record: OMSå†å²è®°å½•

        Returns:
            å¤„ç†ç»“æœ
        """
        draft_id = oms_record.draft_id
        work_type_desc = oms_record.work_type_desc

        self.logger.info(f"ğŸ” å¤„ç†OMSè®°å½•: {draft_id} - {work_type_desc}")

        result = {
            'draft_id': draft_id,
            'work_type_desc': work_type_desc,
            'success': False,
            'action': 'skipped',
            'pgm_id': None,
            'pgm_type': None,
            'files_downloaded': 0,
            'message': ''
        }

        try:
            # 1. æ£€æŸ¥æ˜¯å¦åº”è¯¥å¤„ç†æ­¤è®°å½•
            if not self._should_process_record(oms_record):
                result['message'] = 'è®°å½•ä¸ç¬¦åˆå¤„ç†æ¡ä»¶'
                self.logger.info(f"â­ï¸ è·³è¿‡è®°å½•: {draft_id} - {result['message']}")
                return result

            # 2. ç¡®å®šPGMç±»å‹ï¼ˆET/ATï¼‰
            pgm_type = self._determine_pgm_type(oms_record)
            result['pgm_type'] = pgm_type

            # 3. ç”ŸæˆPGM ID
            pgm_id = self._generate_pgm_id(draft_id, pgm_type, oms_record)
            result['pgm_id'] = pgm_id

            # 4. æ£€æŸ¥PGMæ˜¯å¦å·²å­˜åœ¨
            existing_pgm = self.pgm_repo.get_by_id(pgm_id)

            if existing_pgm:
                # æ›´æ–°ç°æœ‰è®°å½•
                updated = self._update_existing_pgm(existing_pgm, oms_record)
                result['action'] = 'updated' if updated else 'update_failed'
            else:
                # åˆ›å»ºæ–°è®°å½•
                created = self._create_new_pgm(pgm_id, pgm_type, oms_record)
                result['action'] = 'created' if created else 'create_failed'

            if result['action'] in ['created', 'updated']:
                result['success'] = True

                # 5. ä¸‹è½½æ–‡ä»¶ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
                if self._should_download_files(oms_record):
                    files_downloaded = self._download_attached_files(oms_record, pgm_id)
                    result['files_downloaded'] = files_downloaded
                    result['message'] = f'æˆåŠŸå¤„ç†ï¼Œä¸‹è½½{files_downloaded}ä¸ªæ–‡ä»¶'
                else:
                    result['message'] = 'æˆåŠŸå¤„ç†ï¼Œæ— éœ€ä¸‹è½½æ–‡ä»¶'

            return result

        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†å•ä¸ªè®°å½•å¤±è´¥ ({draft_id}): {str(e)}")
            result['message'] = f'å¤„ç†å¤±è´¥: {str(e)}'
            return result

    def _get_new_oms_records(self, processed_draft_ids: set) -> List[PGMOmsHistory]:
        """è·å–æ–°çš„OMSè®°å½•"""
        try:
            # è·å–ä»Šå¤©çš„æ‰€æœ‰è®°å½•
            today = datetime.now().strftime('%Y-%m-%d')
            all_records = self.oms_repo.get_recent_drafts(days=1)

            # è¿‡æ»¤æ‰å·²å¤„ç†çš„
            new_records = [r for r in all_records if r.draft_id not in processed_draft_ids]

            # æŒ‰å·¥ä½œç±»å‹æ’åºï¼Œä¼˜å…ˆå¤„ç†èµ·è‰é˜¶æ®µçš„è®°å½•
            new_records.sort(key=lambda x: x.work_type_no or 0)

            return new_records

        except Exception as e:
            self.logger.error(f"âŒ è·å–æ–°OMSè®°å½•å¤±è´¥: {str(e)}")
            return []

    def _process_single_oms_record(self, oms_record: PGMOmsHistory) -> Dict[str, any]:
        """
        å¤„ç†å•ä¸ªOMSè®°å½•

        Args:
            oms_record: OMSå†å²è®°å½•

        Returns:
            å¤„ç†ç»“æœ
        """
        draft_id = oms_record.draft_id
        work_type_desc = oms_record.work_type_desc

        self.logger.info(f"ğŸ” å¤„ç†OMSè®°å½•: {draft_id} - {work_type_desc}")

        result = {
            'draft_id': draft_id,
            'work_type_desc': work_type_desc,
            'success': False,
            'action': 'skipped',
            'pgm_id': None,
            'pgm_type': None,
            'files_downloaded': 0,
            'message': ''
        }

        try:
            # 1. æ£€æŸ¥æ˜¯å¦åº”è¯¥å¤„ç†æ­¤è®°å½•
            if not self._should_process_record(oms_record):
                result['message'] = 'è®°å½•ä¸ç¬¦åˆå¤„ç†æ¡ä»¶'
                self.logger.info(f"â­ï¸ è·³è¿‡è®°å½•: {draft_id} - {result['message']}")
                return result

            # 2. ç¡®å®šPGMç±»å‹ï¼ˆET/ATï¼‰
            pgm_type = self._determine_pgm_type(oms_record)
            result['pgm_type'] = pgm_type

            # 3. ç”ŸæˆPGM ID
            pgm_id = self._generate_pgm_id(draft_id, pgm_type, oms_record)
            result['pgm_id'] = pgm_id

            # 4. æ£€æŸ¥PGMæ˜¯å¦å·²å­˜åœ¨
            existing_pgm = self.pgm_repo.get_by_id(pgm_id)

            if existing_pgm:
                # æ›´æ–°ç°æœ‰è®°å½•
                updated = self._update_existing_pgm(existing_pgm, oms_record)
                result['action'] = 'updated' if updated else 'update_failed'
            else:
                # åˆ›å»ºæ–°è®°å½•
                created = self._create_new_pgm(pgm_id, pgm_type, oms_record)
                result['action'] = 'created' if created else 'create_failed'

            if result['action'] in ['created', 'updated']:
                result['success'] = True

                # 5. ä¸‹è½½æ–‡ä»¶ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
                if self._should_download_files(oms_record):
                    files_downloaded = self._download_attached_files(oms_record, pgm_id)
                    result['files_downloaded'] = files_downloaded
                    result['message'] = f'æˆåŠŸå¤„ç†ï¼Œä¸‹è½½{files_downloaded}ä¸ªæ–‡ä»¶'
                else:
                    result['message'] = 'æˆåŠŸå¤„ç†ï¼Œæ— éœ€ä¸‹è½½æ–‡ä»¶'

            return result

        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†å•ä¸ªè®°å½•å¤±è´¥ ({draft_id}): {str(e)}")
            result['message'] = f'å¤„ç†å¤±è´¥: {str(e)}'
            return result

    def _should_process_record(self, oms_record: PGMOmsHistory) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å¤„ç†æ­¤è®°å½•"""
        try:
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            if not oms_record.draft_id:
                return False

            # æ£€æŸ¥å·¥ä½œç±»å‹ï¼ˆåªå¤„ç†ç‰¹å®šç±»å‹ï¼‰
            work_type_desc = oms_record.work_type_desc or ''
            process_name = oms_record.process_name or ''

            # åªå¤„ç†åŒ…å«"PGM"æˆ–"Dram"å…³é”®å­—çš„è®°å½•
            keywords = ['PGM', 'DRAM', 'Dram']
            has_keyword = any(keyword in process_name.upper() for keyword in keywords)

            if not has_keyword:
                self.logger.debug(f"â­ï¸ è·³è¿‡éPGMè®°å½•: {process_name}")
                return False

            # æ£€æŸ¥å®ŒæˆçŠ¶æ€ï¼ˆæ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´ï¼‰
            complete_yn = oms_record.complete_yn or ''
            if complete_yn == 'ì™„ë£Œ':  # éŸ©è¯­çš„"å®Œæˆ"
                return True
            elif complete_yn == 'ì§„í–‰ ì¤‘':  # éŸ©è¯­çš„"è¿›è¡Œä¸­"
                return True

            return False

        except Exception as e:
            self.logger.error(f"âŒ æ£€æŸ¥è®°å½•å¤„ç†æ¡ä»¶å¤±è´¥: {str(e)}")
            return False

    def _determine_pgm_type(self, oms_record: PGMOmsHistory) -> str:
        """ç¡®å®šPGMç±»å‹"""
        try:
            process_name = oms_record.process_name or ''
            process_name_upper = process_name.upper()

            if 'ET' in process_name_upper:
                return 'ET'
            elif 'AT' in process_name_upper:
                return 'AT'
            elif 'DRAM' in process_name_upper:
                # é»˜è®¤è¿”å›ETï¼Œå®é™…éœ€è¦æ›´ç²¾ç¡®çš„åˆ¤æ–­
                return 'ET'
            else:
                # é€šè¿‡å…¶ä»–æ–¹å¼åˆ¤æ–­
                return self._guess_pgm_type_by_context(oms_record)

        except Exception as e:
            self.logger.error(f"âŒ ç¡®å®šPGMç±»å‹å¤±è´¥: {str(e)}")
            return 'ET'  # é»˜è®¤è¿”å›ET

    def _guess_pgm_type_by_context(self, oms_record: PGMOmsHistory) -> str:
        """é€šè¿‡ä¸Šä¸‹æ–‡çŒœæµ‹PGMç±»å‹"""
        # è¿™é‡Œå¯ä»¥æ ¹æ®æ›´å¤šä¿¡æ¯è¿›è¡Œåˆ¤æ–­
        # ä¾‹å¦‚ï¼šç”¨æˆ·éƒ¨é—¨ã€å·¥å‚IDç­‰

        fac_id = oms_record.fac_id or ''
        user_id = oms_record.user_id or ''

        # ç®€å•çš„å¯å‘å¼è§„åˆ™
        if 'ET' in user_id.upper() or 'ET' in fac_id.upper():
            return 'ET'
        elif 'AT' in user_id.upper() or 'AT' in fac_id.upper():
            return 'AT'
        else:
            return 'ET'  # é»˜è®¤

    def _generate_pgm_id(self, draft_id: str, pgm_type: str) -> str:
        """ç”ŸæˆPGM ID"""
        # ä½¿ç”¨draft_idå’Œç±»å‹ç»„åˆ
        return f"{pgm_type}_{draft_id}"

    def _create_new_pgm(self, pgm_id: str, pgm_type: str, draft_id: str, server_path: str) -> bool:
        """åˆ›å»ºæ–°çš„PGMè®°å½•"""
        try:
            # åˆ›å»ºPGMæ•°æ®
            pgm_data = {
                'pgm_id': pgm_id,
                'pgm_type': pgm_type,
                'status': PGMStatus.NEW.value,
                'server_path': server_path,
                'next_task': NextTask.VERIFY.value,  # ä¸‹è½½åç›´æ¥éªŒè¯
                'fab': '*',
                'tech': '*',
                'mod_type': '*',
                'grade': '*',
                'pkg': '*',
                'density': '*'
            }

            # æ·»åŠ è·¯å¾„è¯¦æƒ…
            path_details = {
                'draft_id': draft_id,
                'source': 'OMS',
                'created_at': datetime.now().isoformat()
            }
            pgm_data['path_details'] = json.dumps(path_details, ensure_ascii=False)

            # ä¿å­˜åˆ°æ•°æ®åº“
            pgm = self.pgm_repo.create(pgm_data)

            if pgm:
                self.logger.info(f"âœ… åˆ›å»ºæ–°PGMè®°å½•: {pgm_id}")
                return True
            else:
                self.logger.error(f"âŒ åˆ›å»ºPGMè®°å½•å¤±è´¥: {pgm_id}")
                return False

        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºæ–°PGMå¤±è´¥ ({pgm_id}): {str(e)}")
            return False

    def _update_existing_pgm(self, existing_pgm: PGMMain, draft_id: str, pgm_type: str) -> bool:
        """æ›´æ–°ç°æœ‰PGMè®°å½•"""
        try:
            # æ›´æ–°çŠ¶æ€ä¸ºéœ€è¦éªŒè¯
            update_data = {
                'status': PGMStatus.DOWNLOADED.value,
                'next_task': NextTask.VERIFY.value,
                'updated_at': datetime.now()
            }

            # å¦‚æœæœåŠ¡å™¨è·¯å¾„ä¸ºç©ºï¼Œæ›´æ–°å®ƒ
            if not existing_pgm.server_path:
                server_path = self._create_server_path(existing_pgm.pgm_id)
                update_data['server_path'] = server_path

            # æ‰§è¡Œæ›´æ–°
            updated = self.pgm_repo.update(existing_pgm.pgm_id, update_data)

            if updated:
                self.logger.info(f"âœ… æ›´æ–°PGMè®°å½•: {existing_pgm.pgm_id}")
            else:
                self.logger.warning(f"âš ï¸ æ›´æ–°PGMè®°å½•æ— å˜åŒ–: {existing_pgm.pgm_id}")

            return updated

        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°PGMè®°å½•å¤±è´¥ ({existing_pgm.pgm_id}): {str(e)}")
            return False

    def _create_server_path(self, pgm_id: str) -> str:
        """åˆ›å»ºæœåŠ¡å™¨è·¯å¾„"""
        try:
            base_path = self.file_paths.get('local_verify', '')
            if not base_path:
                raise ValueError("æœªé…ç½®æœ¬åœ°éªŒè¯è·¯å¾„")

            # ä½¿ç”¨æ—¥æœŸå­ç›®å½•
            date_str = datetime.now().strftime('%Y%m%d')
            pgm_path = os.path.join(base_path, date_str, pgm_id)

            # åˆ›å»ºç›®å½•
            os.makedirs(pgm_path, exist_ok=True)

            self.logger.debug(f"ğŸ“ åˆ›å»ºæœåŠ¡å™¨è·¯å¾„: {pgm_path}")
            return pgm_path

        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºæœåŠ¡å™¨è·¯å¾„å¤±è´¥: {str(e)}")
            return ''

    def _extract_product_info(self, oms_record: PGMOmsHistory) -> Dict[str, str]:
        """ä»OMSè®°å½•ä¸­æå–äº§å“ä¿¡æ¯"""
        product_info = {}

        try:
            process_name = oms_record.process_name or ''

            # ä»æµç¨‹åç§°ä¸­æå–ä¿¡æ¯ï¼ˆæ ¹æ®å®é™…å‘½åè§„åˆ™ï¼‰
            # ç¤ºä¾‹: "CP16G RD ET PGM Release"
            patterns = [
                (r'(\w+)G', 'density'),  # å¯†åº¦: 16G, 32G
                (r'(\w+)\s+(RD|QD)', 'mod_type'),  # æ¨¡å—ç±»å‹: RD, QD
                (r'(CP|LC|HC|DP)', 'tech'),  # æŠ€æœ¯: CP, LC
                (r'(\w+)\s+DIMM', 'product_type'),  # äº§å“ç±»å‹
            ]

            for pattern, field in patterns:
                match = re.search(pattern, process_name, re.IGNORECASE)
                if match:
                    product_info[field] = match.group(1).upper()

            # è®¾ç½®é»˜è®¤å€¼
            product_info.setdefault('fab', '*')
            product_info.setdefault('tech', '*')
            product_info.setdefault('mod_type', '*')
            product_info.setdefault('grade', '*')
            product_info.setdefault('pkg', '*')
            product_info.setdefault('density', '*')

            self.logger.debug(f"ğŸ“‹ æå–äº§å“ä¿¡æ¯: {product_info}")

        except Exception as e:
            self.logger.error(f"âŒ æå–äº§å“ä¿¡æ¯å¤±è´¥: {str(e)}")
            product_info = {
                'fab': '*', 'tech': '*', 'mod_type': '*',
                'grade': '*', 'pkg': '*', 'density': '*'
            }

        return product_info

    def _should_download_files(self, oms_record: PGMOmsHistory) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥ä¸‹è½½æ–‡ä»¶"""
        # è¿™é‡Œå¯ä»¥æ ¹æ®å·¥ä½œç±»å‹ã€çŠ¶æ€ç­‰å†³å®š
        work_type_desc = oms_record.work_type_desc or ''

        # åªåœ¨å‰å‡ ä¸ªæ­¥éª¤ä¸‹è½½æ–‡ä»¶
        download_stages = ['[1Step] ê¸°ì•ˆ', '[2Step] ì™¸ì£¼ì‚¬ ê²°ê³¼']

        return work_type_desc in download_stages

    def _download_attached_files(self, oms_record: PGMOmsHistory, pgm_id: str) -> int:
        """ä¸‹è½½é™„ä»¶æ–‡ä»¶"""
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®é™…çš„process_idå’Œfile_download_id
        # å½“å‰åªèƒ½æ¨¡æ‹Ÿä¸‹è½½

        self.logger.info(f"ğŸ“¥ éœ€è¦ä¸‹è½½æ–‡ä»¶ï¼Œä½†ç¼ºå°‘å…·ä½“æ–‡ä»¶ä¿¡æ¯: {pgm_id}")
        return 0  # æ¨¡æ‹Ÿä¸‹è½½0ä¸ªæ–‡ä»¶

    def cleanup_old_data(self, days_to_keep: int = 30) -> Dict[str, int]:
        """æ¸…ç†æ—§æ•°æ®"""
        try:
            self.logger.info(f"ğŸ§¹ å¼€å§‹æ¸…ç† {days_to_keep} å¤©å‰çš„æ•°æ®")

            cutoff_date = datetime.now() - timedelta(days=days_to_keep)

            # æ¸…ç†æ—§çš„PGMè®°å½•ï¼ˆæ ¹æ®çŠ¶æ€ï¼‰
            old_pgms = self.pgm_repo.session.query(PGMMain).filter(
                PGMMain.created_at < cutoff_date,
                PGMMain.status.in_([PGMStatus.MONITORED, PGMStatus.VERIFY_FAILED])
            ).all()

            deleted_pgms = 0
            for pgm in old_pgms:
                # åˆ é™¤å¯¹åº”çš„æ–‡ä»¶
                if pgm.server_path and os.path.exists(pgm.server_path):
                    try:
                        shutil.rmtree(pgm.server_path)
                        self.logger.debug(f"ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶ç›®å½•: {pgm.server_path}")
                    except Exception as e:
                        self.logger.error(f"âŒ åˆ é™¤æ–‡ä»¶ç›®å½•å¤±è´¥: {str(e)}")

                # åˆ é™¤æ•°æ®åº“è®°å½•
                self.pgm_repo.delete(pgm.pgm_id)
                deleted_pgms += 1

            # æ¸…ç†æ—§çš„OMSè®°å½•
            old_oms_records = self.oms_repo.session.query(PGMOmsHistory).filter(
                PGMOmsHistory.fetched_at < cutoff_date
            ).delete()

            self.pgm_repo.commit()

            self.logger.info(f"âœ… æ•°æ®æ¸…ç†å®Œæˆ - åˆ é™¤PGMè®°å½•: {deleted_pgms}, OMSè®°å½•: {old_oms_records}")

            return {
                'deleted_pgms': deleted_pgms,
                'deleted_oms_records': old_oms_records
            }

        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®æ¸…ç†å¤±è´¥: {str(e)}")
            return {'deleted_pgms': 0, 'deleted_oms_records': 0}

    def _download_files_for_draft(self, draft_id: str, server_path: str) -> Dict[str, int]:
        """ä¸ºè‰ç¨¿ä¸‹è½½æ–‡ä»¶"""
        result = {
            'downloaded': 0,
            'errors': 0,
            'files': []
        }

        try:
            self.logger.info(f"ğŸ“¥ å¼€å§‹ä¸ºè‰ç¨¿ {draft_id} ä¸‹è½½æ–‡ä»¶")

            # 1. è·å–process_idå’Œwork_sequence
            process_info = self._get_process_info_for_draft(draft_id)
            if not process_info:
                self.logger.warning(f"âš ï¸ æ— æ³•è·å–processä¿¡æ¯: {draft_id}")
                return result

            process_id = process_info['process_id']
            work_sequence = process_info['work_sequence']

            if not process_id:
                self.logger.warning(f"âš ï¸ process_idä¸ºç©º: {draft_id}")
                return result

            # 2. è·å–æ–‡ä»¶ä¸‹è½½ä¿¡æ¯
            file_info_list = self._get_file_info_for_process(process_id, work_sequence)

            if not file_info_list:
                self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ–‡ä»¶ä¸‹è½½ä¿¡æ¯: {draft_id}")
                return result

            # 3. ä¸‹è½½æ¯ä¸ªæ–‡ä»¶
            for file_info in file_info_list:
                try:
                    file_download_id = file_info.get('file_download_id')
                    file_name = file_info.get('file_name')
                    file_size = file_info.get('size', 0)

                    if not file_download_id or not file_name:
                        self.logger.warning(f"âš ï¸ æ–‡ä»¶ä¿¡æ¯ä¸å®Œæ•´: {file_info}")
                        continue

                    # æ„å»ºä¿å­˜è·¯å¾„
                    save_path = os.path.join(server_path, file_name)

                    # ä¸‹è½½æ–‡ä»¶ - ä½¿ç”¨OMSClientçš„download_fileæ–¹æ³•
                    self.logger.info(f"ğŸ“¥ ä¸‹è½½æ–‡ä»¶: {file_name} (ID: {file_download_id})")

                    download_success = self.oms_client.download_file(
                        file_download_id=file_download_id,
                        bpms_process_id=process_id,
                        bpms_work_sequence=work_sequence,
                        save_path=save_path
                    )

                    if download_success:
                        # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸä¸‹è½½
                        if os.path.exists(save_path) and os.path.getsize(save_path) > 0:
                            actual_size = os.path.getsize(save_path)
                            result['downloaded'] += 1
                            result['files'].append({
                                'name': file_name,
                                'expected_size': file_size,
                                'actual_size': actual_size,
                                'path': save_path
                            })
                            self.logger.info(f"âœ… ä¸‹è½½æ–‡ä»¶æˆåŠŸ: {file_name} ({actual_size}/{file_size} bytes)")
                        else:
                            result['errors'] += 1
                            self.logger.error(f"âŒ æ–‡ä»¶ä¸‹è½½åéªŒè¯å¤±è´¥: {save_path}")
                    else:
                        result['errors'] += 1
                        self.logger.error(f"âŒ ä¸‹è½½æ–‡ä»¶å¤±è´¥: {file_name}")

                except Exception as e:
                    result['errors'] += 1
                    self.logger.error(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {str(e)}")

            self.logger.info(f"ğŸ“Š æ–‡ä»¶ä¸‹è½½å®Œæˆ: {draft_id} - æˆåŠŸ{result['downloaded']}ä¸ª, å¤±è´¥{result['errors']}ä¸ª")

            return result

        except Exception as e:
            self.logger.error(f"âŒ ä¸‹è½½æ–‡ä»¶å¤±è´¥ ({draft_id}): {str(e)}")
            result['errors'] += 1
            return result

    def _get_file_info_for_process(self, process_id: str, work_sequence: int) -> List[Dict[str, any]]:
        """è·å–æµç¨‹çš„æ–‡ä»¶ä¿¡æ¯"""
        file_info_list = []

        try:
            # 1. å°è¯•è·å–ETæ–‡ä»¶ä¿¡æ¯
            et_details = self.oms_client.get_et_pgm_details(process_id, work_sequence)
            if et_details and 'file_info' in et_details:
                for file_info in et_details['file_info']:
                    file_info['pgm_type'] = 'ET'
                    file_info['process_id'] = process_id
                    file_info['work_sequence'] = work_sequence
                    file_info_list.append(file_info)

            # 2. å°è¯•è·å–ATæ–‡ä»¶ä¿¡æ¯
            at_details = self.oms_client.get_at_pgm_details(process_id, work_sequence)
            if at_details and 'file_info' in at_details:
                for file_info in at_details['file_info']:
                    file_info['pgm_type'] = 'AT'
                    file_info['process_id'] = process_id
                    file_info['work_sequence'] = work_sequence
                    file_info_list.append(file_info)

            self.logger.debug(f"ğŸ“‹ è·å–åˆ° {len(file_info_list)} ä¸ªæ–‡ä»¶ä¸‹è½½ä¿¡æ¯")

        except Exception as e:
            self.logger.error(f"âŒ è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {str(e)}")

        return file_info_list

    def _get_process_info_for_draft(self, draft_id: str) -> Optional[Dict[str, any]]:
        """è·å–è‰ç¨¿çš„processä¿¡æ¯"""
        try:
            # ä»æ•°æ®åº“æŸ¥è¯¢
            session = self.oms_repo.session
            records = session.query(PGMOmsHistory).filter(
                PGMOmsHistory.draft_id == draft_id
            ).order_by(PGMOmsHistory.fetched_at.desc()).all()

            if records:
                # å–æœ€æ–°çš„è®°å½•
                latest_record = records[0]
                return {
                    'process_id': latest_record.process_id,
                    'work_sequence': self._extract_work_sequence(latest_record),
                    'work_type_desc': latest_record.work_type_desc
                }

            self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°è‰ç¨¿è®°å½•: {draft_id}")
            return None

        except Exception as e:
            self.logger.error(f"âŒ è·å–processä¿¡æ¯å¤±è´¥: {str(e)}")
            return None

    def _extract_work_sequence(self, oms_record: PGMOmsHistory) -> int:
        """æå–å·¥ä½œåºåˆ—å·"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®ç»“æ„æå–work_sequence
        # æš‚æ—¶è¿”å›é»˜è®¤å€¼1ï¼Œå®é™…éœ€è¦æ ¹æ®æ•°æ®è°ƒæ•´
        return 1

# æ›´æ–°OMSå®¢æˆ·ç«¯ä»¥æ”¯æŒæ–‡ä»¶ä¸‹è½½
class EnhancedOMSClient(OMSClient):
    """å¢å¼ºçš„OMSå®¢æˆ·ç«¯ï¼ˆæ”¯æŒæ–‡ä»¶ä¸‹è½½ï¼‰"""

    def get_file_download_info(self, draft_id: str) -> List[Dict[str, any]]:
        """è·å–æ–‡ä»¶ä¸‹è½½ä¿¡æ¯"""
        # è¿™é‡Œéœ€è¦è°ƒç”¨OMS APIè·å–æ–‡ä»¶ä¿¡æ¯
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®

        return [
            {
                'file_download_id': f'mock_{draft_id}_1',
                'file_name': f'{draft_id}.zip',
                'size': 1024000,
                'bpms_process_id': 'mock_process_id',
                'bpms_work_sequence': 1
            },
            {
                'file_download_id': f'mock_{draft_id}_2',
                'file_name': 'HESS.xlsx',
                'size': 512000,
                'bpms_process_id': 'mock_process_id',
                'bpms_work_sequence': 1
            }
        ]