"""
OMSå®¢æˆ·ç«¯æ¨¡å— - è´Ÿè´£ä¸SK Hynix OMSç³»ç»Ÿäº¤äº’
"""
import requests
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from urllib.parse import urljoin
import time
import hashlib

from utils.config_loader import get_config
from utils.logger import get_pgm_logger
from database.models import PGMOmsHistory
from database.repositories import PGMOmsHistoryRepository


class OMSClient:
    """OMSç³»ç»Ÿå®¢æˆ·ç«¯"""

    def __init__(self):
        """åˆå§‹åŒ–OMSå®¢æˆ·ç«¯"""
        self.logger = get_pgm_logger().get_logger('oms')
        self.config = get_config().get_oms_config()
        self.token = None
        self.token_expiry = None

        # ç¼“å­˜æœ€è¿‘æŸ¥è¯¢çš„PGMæ•°æ®ï¼ˆå¯é€‰ï¼‰
        self.cache = {}
        self.cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜

        self.logger.info("ğŸ”§ OMSå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

    def _get_headers(self) -> Dict[str, str]:
        """è·å–è¯·æ±‚å¤´"""
        headers = self.config['headers'].copy()

        if self.token:
            headers['Authorization'] = self.token

        return headers

    def login(self) -> bool:
        """
        ç™»å½•OMSç³»ç»Ÿè·å–token

        Returns:
            æ˜¯å¦ç™»å½•æˆåŠŸ
        """
        try:
            # å¦‚æœtokenä»ç„¶æœ‰æ•ˆï¼Œç›´æ¥ä½¿ç”¨
            if self.token and self.token_expiry and datetime.now() < self.token_expiry:
                self.logger.debug("âœ… ä½¿ç”¨ç¼“å­˜çš„OMS token")
                return True

            login_url = urljoin(self.config['api_base'], self.config['auth_endpoint'])

            login_data = {
                "id": self.config['user_id'],
                "password": self.config['password']
            }

            self.logger.info(f"ğŸ”‘ æ­£åœ¨ç™»å½•OMSç³»ç»Ÿ: {self.config['user_id']}")
            self.logger.debug(f"ç™»å½•URL: {login_url}")

            response = requests.post(
                login_url,
                json=login_data,
                headers=self._get_headers(),
                timeout=30
            )

            response.raise_for_status()

            result = response.json()
            token = result.get("token")

            if not token:
                self.logger.error("âŒ OMSç™»å½•å¤±è´¥: å“åº”ä¸­æœªæ‰¾åˆ°token")
                return False

            self.token = f"Bearer {token}"

            # è®¾ç½®tokenè¿‡æœŸæ—¶é—´ï¼ˆå‡è®¾tokenæœ‰æ•ˆæœŸä¸º1å°æ—¶ï¼‰
            self.token_expiry = datetime.now() + timedelta(minutes=55)

            self.logger.info("âœ… OMSç™»å½•æˆåŠŸ")
            return True

        except requests.exceptions.RequestException as e:
            self.logger.error(f"âŒ OMSç™»å½•å¤±è´¥ (ç½‘ç»œé”™è¯¯): {str(e)}")
            return False
        except json.JSONDecodeError as e:
            self.logger.error(f"âŒ OMSç™»å½•å¤±è´¥ (JSONè§£æé”™è¯¯): {str(e)}")
            return False
        except Exception as e:
            self.logger.error(f"âŒ OMSç™»å½•å¤±è´¥ (æœªçŸ¥é”™è¯¯): {str(e)}")
            return False

    def _ensure_login(self) -> bool:
        """ç¡®ä¿å·²ç™»å½•"""
        if not self.token or (self.token_expiry and datetime.now() >= self.token_expiry):
            return self.login()
        return True

    def get_pgm_distribution_status(self,
                                    begin_date: Optional[str] = None,
                                    end_date: Optional[str] = None,
                                    force_refresh: bool = False) -> List[Dict[str, Any]]:
        """
        è·å–PGMåˆ†å‘çŠ¶æ€

        Args:
            begin_date: å¼€å§‹æ—¥æœŸ (æ ¼å¼: "YYYY-MM-DD HH:MM:SS")
            end_date: ç»“æŸæ—¥æœŸ (æ ¼å¼: "YYYY-MM-DD HH:MM:SS")
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜

        Returns:
            PGMåˆ†å‘çŠ¶æ€åˆ—è¡¨
        """
        cache_key = f"distribution_status_{begin_date}_{end_date}"

        # æ£€æŸ¥ç¼“å­˜
        if not force_refresh and cache_key in self.cache:
            cache_data, cache_time = self.cache[cache_key]
            if time.time() - cache_time < self.cache_ttl:
                self.logger.debug(f"ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„PGMåˆ†å‘çŠ¶æ€æ•°æ®")
                return cache_data

        try:
            # ç¡®ä¿å·²ç™»å½•
            if not self._ensure_login():
                self.logger.error("âŒ è·å–PGMåˆ†å‘çŠ¶æ€å¤±è´¥: ç™»å½•æ— æ•ˆ")
                return []

            # è®¾ç½®é»˜è®¤æ—¥æœŸèŒƒå›´
            if not begin_date or not end_date:
                today = datetime.now()
                begin_date = (today - timedelta(days=11)).strftime("%Y-%m-%d 07:00:00")
                end_date = (today + timedelta(days=1)).strftime("%Y-%m-%d 07:00:00")

            url = urljoin(self.config['api_base'], self.config['data_endpoint'])

            params = {
                "factoryId": "OSMOD",
                "companyId": "HITECH",
                "beginDate": begin_date,
                "endDate": end_date
            }

            self.logger.info(f"ğŸ“‹ è·å–PGMåˆ†å‘çŠ¶æ€: {begin_date} åˆ° {end_date}")
            self.logger.debug(f"è¯·æ±‚URL: {url}")
            self.logger.debug(f"è¯·æ±‚å‚æ•°: {params}")

            start_time = time.time()
            response = requests.get(
                url,
                params=params,
                headers=self._get_headers(),
                timeout=60
            )
            response_time = time.time() - start_time

            response.raise_for_status()

            data = response.json()

            self.logger.info(f"âœ… æˆåŠŸè·å–PGMåˆ†å‘çŠ¶æ€ï¼Œå…±{len(data)}æ¡è®°å½•")
            self.logger.debug(f"å“åº”æ—¶é—´: {response_time:.2f}ç§’")

            # ç¼“å­˜ç»“æœ
            self.cache[cache_key] = (data, time.time())

            return data

        except requests.exceptions.RequestException as e:
            self.logger.error(f"âŒ è·å–PGMåˆ†å‘çŠ¶æ€å¤±è´¥ (ç½‘ç»œé”™è¯¯): {str(e)}")

            # ç½‘ç»œé”™è¯¯æ—¶å°è¯•åˆ·æ–°tokenå¹¶é‡è¯•ä¸€æ¬¡
            if "401" in str(e) or "403" in str(e):
                self.logger.info("ğŸ”„ Tokenå¯èƒ½è¿‡æœŸï¼Œå°è¯•é‡æ–°ç™»å½•...")
                self.token = None
                return self.get_pgm_distribution_status(begin_date, end_date, force_refresh)

            return []
        except json.JSONDecodeError as e:
            self.logger.error(f"âŒ è·å–PGMåˆ†å‘çŠ¶æ€å¤±è´¥ (JSONè§£æé”™è¯¯): {str(e)}")
            return []
        except Exception as e:
            self.logger.error(f"âŒ è·å–PGMåˆ†å‘çŠ¶æ€å¤±è´¥ (æœªçŸ¥é”™è¯¯): {str(e)}")
            return []

    def get_new_pgms(self, last_check_time: Optional[datetime] = None) -> List[Dict[str, Any]]:
        """
        è·å–æ–°çš„PGMï¼ˆè‡ªä¸Šæ¬¡æ£€æŸ¥åæ–°å¢çš„ï¼‰

        Args:
            last_check_time: ä¸Šæ¬¡æ£€æŸ¥æ—¶é—´

        Returns:
            æ–°çš„PGMåˆ—è¡¨
        """
        try:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šä¸Šæ¬¡æ£€æŸ¥æ—¶é—´ï¼Œé»˜è®¤æ£€æŸ¥è¿‡å»1å¤©çš„æ•°æ®
            if not last_check_time:
                last_check_time = datetime.now() - timedelta(days=1)

            begin_date = last_check_time.strftime("%Y-%m-%d %H:%M:%S")
            end_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            all_pgms = self.get_pgm_distribution_status(begin_date, end_date)

            # è¿‡æ»¤å‡ºæ–°çš„PGMï¼ˆè¿™é‡Œå¯ä»¥æ ¹æ®ä¸šåŠ¡é€»è¾‘è¿›ä¸€æ­¥è¿‡æ»¤ï¼‰
            new_pgms = []
            for pgm in all_pgms:
                # ç¤ºä¾‹è¿‡æ»¤é€»è¾‘ï¼šåªè·å–ç‰¹å®šçŠ¶æ€æˆ–ç±»å‹çš„PGM
                work_type_desc = pgm.get('workTypeDesc', '')
                complete_yn = pgm.get('completeYn', '')

                # å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´è¿‡æ»¤æ¡ä»¶
                if 'PGM' in str(pgm.get('processName', '')).upper():
                    new_pgms.append(pgm)

            self.logger.info(f"ğŸ“Š å‘ç° {len(new_pgms)} ä¸ªæ–°çš„PGM")

            return new_pgms

        except Exception as e:
            self.logger.error(f"âŒ è·å–æ–°PGMå¤±è´¥: {str(e)}")
            return []

    def download_pgm_attachment(self, draft_id: str,
                                save_path: str) -> bool:
        """
        ä¸‹è½½PGMé™„ä»¶

        Args:
            draft_id: è‰ç¨¿ID
            save_path: ä¿å­˜è·¯å¾„

        Returns:
            æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        try:
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„OMS APIæ¥è°ƒæ•´
            # å½“å‰ä»£ç æ˜¯åŸºäºç°æœ‰oms_autoV2.pyçš„é€»è¾‘

            # ç¤ºä¾‹ï¼šå‡è®¾æœ‰ä¸€ä¸ªä¸‹è½½é™„ä»¶çš„API
            # download_url = f"{self.config['api_base']}/attachments/{draft_id}"

            # response = requests.get(download_url, headers=self._get_headers(), stream=True)
            # with open(save_path, 'wb') as f:
            #     for chunk in response.iter_content(chunk_size=8192):
            #         f.write(chunk)

            self.logger.info(f"ğŸ“¥ ä¸‹è½½PGMé™„ä»¶: {draft_id} -> {save_path}")

            # æš‚æ—¶è¿”å›æˆåŠŸï¼ˆå®é™…éœ€è¦æ ¹æ®OMS APIå®ç°ï¼‰
            return True

        except Exception as e:
            self.logger.error(f"âŒ ä¸‹è½½PGMé™„ä»¶å¤±è´¥ ({draft_id}): {str(e)}")
            return False

    def get_pgm_details(self, draft_id: str) -> Optional[Dict[str, Any]]:
        """
        è·å–PGMè¯¦ç»†ä¿¡æ¯

        Args:
            draft_id: è‰ç¨¿ID

        Returns:
            PGMè¯¦ç»†ä¿¡æ¯
        """
        try:
            # ä»åˆ†å‘çŠ¶æ€æ•°æ®ä¸­æŸ¥æ‰¾ç‰¹å®šdraft_id
            # è¿™é‡Œå¯ä»¥è°ƒç”¨å•ç‹¬çš„APIï¼Œæˆ–è€…ä»ç¼“å­˜ä¸­æŸ¥æ‰¾

            # ä¸´æ—¶å®ç°ï¼šè·å–æœ€è¿‘30å¤©çš„æ•°æ®å¹¶æŸ¥æ‰¾
            all_pgms = self.get_pgm_distribution_status()

            for pgm in all_pgms:
                if pgm.get('draftId') == draft_id:
                    return pgm

            self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°PGMè¯¦ç»†ä¿¡æ¯: {draft_id}")
            return None

        except Exception as e:
            self.logger.error(f"âŒ è·å–PGMè¯¦ç»†ä¿¡æ¯å¤±è´¥ ({draft_id}): {str(e)}")
            return None


class OMSDataProcessor:
    """OMSæ•°æ®å¤„ç†å™¨"""

    # work_type_desc åˆ° work_type_no çš„æ˜ å°„
    WORK_TYPE_MAP = {
        '[1Step] ê¸°ì•ˆ': 1,
        '[2Step] ì™¸ì£¼ì‚¬ ê²°ê³¼': 2,
        '[3Step] ìµœì¢…ìŠ¹ì¸': 3,
        '[4Step] ì–‘ì‚°ì ìš©': 4
    }

    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨"""
        self.logger = get_pgm_logger().get_logger('oms_processor')
        self.oms_client = OMSClient()
        self.repository = PGMOmsHistoryRepository()

    def fetch_and_process_latest_data(self) -> bool:
        """
        è·å–å¹¶å¤„ç†æœ€æ–°çš„OMSæ•°æ®

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            self.logger.info("ğŸ”„ å¼€å§‹è·å–æœ€æ–°OMSæ•°æ®")

            # 1. è·å–æœ€æ–°æ•°æ®ï¼ˆé»˜è®¤è·å–11å¤©å†…çš„æ•°æ®ï¼‰
            pgm_data = self.oms_client.get_pgm_distribution_status()

            if not pgm_data:
                self.logger.warning("âš ï¸ æœªè·å–åˆ°OMSæ•°æ®")
                return False

            self.logger.info(f"ğŸ“Š è·å–åˆ° {len(pgm_data)} æ¡OMSè®°å½•")

            # 2. å¤„ç†æ¯æ¡è®°å½•
            success_count = 0
            error_count = 0

            for item in pgm_data:
                try:
                    processed_data = self._process_single_record(item)

                    if processed_data:
                        # ä¿å­˜åˆ°æ•°æ®åº“
                        if self.repository.upsert_oms_record(processed_data):
                            success_count += 1
                        else:
                            error_count += 1
                    else:
                        error_count += 1

                except Exception as e:
                    self.logger.error(f"âŒ å¤„ç†OMSè®°å½•å¤±è´¥: {str(e)}")
                    error_count += 1

            # 3. è®°å½•ç»“æœ
            self.logger.info(f"âœ… OMSæ•°æ®å¤„ç†å®Œæˆ - æˆåŠŸ: {success_count}, å¤±è´¥: {error_count}")

            return success_count > 0

        except Exception as e:
            self.logger.error(f"âŒ OMSæ•°æ®å¤„ç†å¤±è´¥: {str(e)}")
            return False

    def _process_single_record(self, raw_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        å¤„ç†å•æ¡OMSè®°å½•

        Args:
            raw_data: åŸå§‹æ•°æ®

        Returns:
            å¤„ç†åçš„æ•°æ®
        """
        try:
            # æå–å…³é”®å­—æ®µ
            draft_id = raw_data.get('draftId')
            work_type_desc = raw_data.get('workTypeDesc')

            if not draft_id or not work_type_desc:
                self.logger.warning(f"âš ï¸ OMSè®°å½•ç¼ºå°‘å…³é”®å­—æ®µ: {raw_data}")
                return None

            # æ˜ å°„ work_type_no
            work_type_no = self.WORK_TYPE_MAP.get(work_type_desc)

            # æ„å»ºå¤„ç†åçš„æ•°æ®
            processed_data = {
                'draft_id': draft_id,
                'work_type_desc': work_type_desc,
                'process_id': raw_data.get('processId'),
                'work_type_no': work_type_no,
                'work_status': raw_data.get('workStatus'),
                'work_start_tm': raw_data.get('workStartTm'),
                'complete_yn': raw_data.get('completeYn'),
                'user_id': raw_data.get('userId'),
                'user_name': raw_data.get('userName'),
                'fac_id': raw_data.get('facId'),
                'process_name': raw_data.get('processName'),
                'process_status_code': raw_data.get('processStatusCode')
            }

            # è®¡ç®—TATç›¸å…³ä¿¡æ¯
            if work_type_no and raw_data.get('workStartTm'):
                tat_info = self._calculate_tat_info(
                    raw_data['workStartTm'],
                    work_type_no
                )
                processed_data.update(tat_info)

            return processed_data

        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†å•æ¡OMSè®°å½•å¤±è´¥: {str(e)}")
            return None

    def _calculate_tat_info(self, work_start_tm: str, work_type_no: int) -> Dict[str, Any]:
        """
        è®¡ç®—TATç›¸å…³ä¿¡æ¯

        Args:
            work_start_tm: å·¥ä½œå¼€å§‹æ—¶é—´
            work_type_no: å·¥ä½œç±»å‹ç¼–å·

        Returns:
            TATä¿¡æ¯å­—å…¸
        """
        try:
            # è§£ææ—¶é—´å­—ç¬¦ä¸²ï¼ˆæ ¼å¼å¯èƒ½ä¸º "MM/DD HH:MM" æˆ– "YYYY/MM/DD HH:MM"ï¼‰
            try:
                # å°è¯•æ ¼å¼ "YYYY/MM/DD HH:MM"
                if '/' in work_start_tm and ':' in work_start_tm:
                    parts = work_start_tm.split()
                    if len(parts) == 2:
                        date_part, time_part = parts
                        date_parts = date_part.split('/')

                        if len(date_parts) == 2:  # "MM/DD"
                            # æ·»åŠ å½“å‰å¹´ä»½
                            current_year = datetime.now().year
                            start_time = datetime.strptime(
                                f"{current_year}/{date_part} {time_part}",
                                "%Y/%m/%d %H:%M"
                            )
                        elif len(date_parts) == 3:  # "YYYY/MM/DD"
                            start_time = datetime.strptime(work_start_tm, "%Y/%m/%d %H:%M")
                        else:
                            start_time = datetime.now()
                    else:
                        start_time = datetime.now()
                else:
                    start_time = datetime.now()
            except:
                start_time = datetime.now()

            # è®¡ç®—TATï¼ˆå¤©æ•°ï¼‰
            tat_days = (datetime.now() - start_time).total_seconds() / (24 * 3600)
            tat_days = round(tat_days, 2)

            # è®¡ç®—marking
            tat_marking = self._calculate_tat_marking(tat_days)

            # è®¡ç®—info_object
            info_object = "Hitech" if work_type_no in [2, 4] else "All"

            return {
                'tat_days': tat_days,
                'tat_marking': tat_marking,
                'info_object': info_object
            }

        except Exception as e:
            self.logger.error(f"âŒ è®¡ç®—TATä¿¡æ¯å¤±è´¥ ({work_start_tm}): {str(e)}")
            return {}

    def _calculate_tat_marking(self, tat_days: float) -> str:
        """
        æ ¹æ®TATè®¡ç®—marking

        Args:
            tat_days: TATå¤©æ•°

        Returns:
            markingå­—ç¬¦ä¸²
        """
        try:
            config = get_config().get_email_config()
            thresholds = config.get('tat_thresholds', {})

            alarm_hours = thresholds.get('alarm_hours', 72)
            warning_hours = thresholds.get('warning_hours', 48)
            notice_hours = thresholds.get('notice_hours', 24)

            tat_hours = tat_days * 24

            if tat_hours > alarm_hours:
                return "Alarm"
            elif tat_hours > warning_hours:
                return "Warning"
            elif tat_hours > notice_hours:
                return "Notice"
            else:
                return "Normal"

        except:
            # é»˜è®¤é˜ˆå€¼
            if tat_days > 3:
                return "Alarm"
            elif tat_days > 2:
                return "Warning"
            elif tat_days > 1:
                return "Notice"
            else:
                return "Normal"

    def check_tat_alarms(self) -> List[Dict[str, Any]]:
        """
        æ£€æŸ¥TATè¶…æ—¶å¹¶è¿”å›æŠ¥è­¦ä¿¡æ¯

        Returns:
            æŠ¥è­¦ä¿¡æ¯åˆ—è¡¨
        """
        try:
            self.logger.info("ğŸ” æ£€æŸ¥TATè¶…æ—¶æŠ¥è­¦")

            # è·å–æœ€è¿‘çš„OMSè®°å½•
            recent_records = self.repository.get_recent_drafts(days=30)

            alarms = []
            for record in recent_records:
                try:
                    # è®¡ç®—TAT
                    if record.work_start_tm and record.work_type_no:
                        tat_info = self._calculate_tat_info(
                            record.work_start_tm,
                            record.work_type_no
                        )

                        tat_marking = tat_info.get('tat_marking', 'Normal')

                        # å¦‚æœæ˜¯Alarmçº§åˆ«ï¼Œç”ŸæˆæŠ¥è­¦ä¿¡æ¯
                        if tat_marking == 'Alarm':
                            alarm_info = {
                                'draft_id': record.draft_id,
                                'work_type_desc': record.work_type_desc,
                                'work_start_tm': record.work_start_tm,
                                'tat_days': tat_info.get('tat_days'),
                                'tat_marking': tat_marking,
                                'info_object': tat_info.get('info_object'),
                                'user_name': record.user_name,
                                'process_name': record.process_name
                            }
                            alarms.append(alarm_info)

                except Exception as e:
                    self.logger.error(f"âŒ æ£€æŸ¥å•æ¡è®°å½•TATå¤±è´¥: {str(e)}")
                    continue

            self.logger.info(f"âš ï¸ å‘ç° {len(alarms)} ä¸ªTATè¶…æ—¶æŠ¥è­¦")

            return alarms

        except Exception as e:
            self.logger.error(f"âŒ æ£€æŸ¥TATæŠ¥è­¦å¤±è´¥: {str(e)}")
            return []


def test_oms_client():
    """æµ‹è¯•OMSå®¢æˆ·ç«¯"""
    print("=" * 60)
    print("OMSå®¢æˆ·ç«¯æµ‹è¯•")
    print("=" * 60)

    logger = get_pgm_logger()
    logger.log_execution_start("OMSå®¢æˆ·ç«¯æµ‹è¯•")

    try:
        # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯
        oms_client = OMSClient()

        # 2. æµ‹è¯•ç™»å½•
        print("ğŸ”‘ æµ‹è¯•OMSç™»å½•...")
        if oms_client.login():
            print("âœ… OMSç™»å½•æˆåŠŸ")
        else:
            print("âŒ OMSç™»å½•å¤±è´¥")
            return False

        # 3. æµ‹è¯•è·å–æ•°æ®
        print("ğŸ“‹ æµ‹è¯•è·å–PGMåˆ†å‘çŠ¶æ€...")
        pgm_data = oms_client.get_pgm_distribution_status()

        if pgm_data:
            print(f"âœ… æˆåŠŸè·å– {len(pgm_data)} æ¡PGMæ•°æ®")

            # æ˜¾ç¤ºå‰å‡ æ¡æ•°æ®
            for i, item in enumerate(pgm_data[:3]):
                print(f"  {i + 1}. {item.get('draftId', 'N/A')} - {item.get('processName', 'N/A')}")
        else:
            print("âŒ è·å–PGMæ•°æ®å¤±è´¥")
            return False

        # 4. æµ‹è¯•æ•°æ®å¤„ç†
        print("ğŸ”„ æµ‹è¯•æ•°æ®å¤„ç†...")
        processor = OMSDataProcessor()

        if processor.fetch_and_process_latest_data():
            print("âœ… OMSæ•°æ®å¤„ç†æˆåŠŸ")
        else:
            print("âŒ OMSæ•°æ®å¤„ç†å¤±è´¥")

        # 5. æµ‹è¯•TATæŠ¥è­¦æ£€æŸ¥
        print("ğŸ” æµ‹è¯•TATæŠ¥è­¦æ£€æŸ¥...")
        alarms = processor.check_tat_alarms()

        if alarms:
            print(f"âš ï¸ å‘ç° {len(alarms)} ä¸ªTATæŠ¥è­¦:")
            for alarm in alarms[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"  - {alarm['draft_id']}: TAT {alarm['tat_days']}å¤©")
        else:
            print("âœ… æœªå‘ç°TATæŠ¥è­¦")

        logger.log_execution_end("OMSå®¢æˆ·ç«¯æµ‹è¯•", success=True)
        return True

    except Exception as e:
        logger.log_execution_end("OMSå®¢æˆ·ç«¯æµ‹è¯•", success=False, message=str(e))
        print(f"âŒ OMSå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


if __name__ == "__main__":
    test_oms_client()